# -*- coding: utf-8 -*-
"""RGB/IR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VgV8HTwjcQ2KFsklV_-Kk4_Jz7OaQvsS
"""

import zipfile
with zipfile.ZipFile("rgb_ir_dataset.zip", "r") as zip_ref:
    zip_ref.extractall("rgb_ir_dataset")

import tensorflow as tf

img_size = (128, 128)
batch_size = 16

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "rgb_ir_dataset",
    validation_split=0.2,
    subset="training",
    seed=42,
    image_size=img_size,
    batch_size=batch_size
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "rgb_ir_dataset",
    validation_split=0.2,
    subset="validation",
    seed=42,
    image_size=img_size,
    batch_size=batch_size
)
class_names = train_ds.class_names
print(class_names)

# Normalize the data (important)
normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))

# train_ds.shape
for images, labels in train_ds.take(1):
    print("Image shape:", images.shape)
    print("Labels shape:", labels.shape)
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')  # 2 classes
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_ds, validation_data=val_ds, epochs=10)

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(acc))

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

from google.colab import files
uploaded = files.upload()

from tensorflow.keras.utils import load_img, img_to_array
import numpy as np

test_img_path = list(uploaded.keys())[0]

img = load_img(test_img_path, target_size=(128, 128))
img_array = img_to_array(img)
img_array = img_array / 255.0  # Normalize
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

prediction = model.predict(img_array)

if prediction[0][0] > 0.5:
    print("Prediction: IR image")
else:
    print("Prediction: RGB image")

print("Raw model output:", prediction)

# Save the model to a file
model.save('rgb_ir_model.h5')  # Saves the model as a .h5 file



















